{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 행렬 요인화(MF) 기반 추천 시스템 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "mpl.rc('font', family='NanumGothic') # 폰트 설정\n",
    "mpl.rc('axes', unicode_minus=False) # 유니코드에서 음수 부호 설정\n",
    "\n",
    "# 차트 스타일 설정\n",
    "sns.set(font=\"NanumGothic\", rc={\"axes.unicode_minus\":False}, style='darkgrid')\n",
    "plt.rc(\"figure\", figsize=(10,8))\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "print(surprise.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# ml-100k: 10만 개 평점 데이터, 무비렌즈 사이트에서 제공하는 과거 데이터 셋 ml-100k을 불러왔다.\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# surprise의 train_test_split() 사용, 10만 개의 데이터를 train 75,000, test 25,000으로 나누었다.\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x12426c89108>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD\n",
    "\n",
    "# SVD를 이용한 잠재 요인 협업 필터링\n",
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid='196', iid='302', r_ui=None, est=4.40664512877181, details={'was_impossible': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 아이디(uid), 아이템 아이디(iid)는 문자열로 입력\n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "\n",
    "# 추천 예측 평점 (.predict)\n",
    "pred = algo.predict(uid, iid)\n",
    "pred\n",
    "# surprise에서 추천을 예측하는 메소드는 test()와 predict()가 있다.\n",
    "# predict()는 개별 사용자의 아이템에 대한 추천 평점을 예측하며 prediction 객체를 반환한다.\n",
    "# prediction 객체는 사용자 아이디(uid), 아이템 아이디(iid), 실제 평점(r_ui), 예측 평점(est)를 튜플 형태로 가진다.\n",
    "# prediction 객체의 details속성은 추천 예측을 할 수 없는 경우 True, 아닌 경우 False이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.6189169617429, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.6235797360547557, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=4.177448313971358, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.264314206124555, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.05410191787773, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추천 예측 평점 (.test)\n",
    "predictions = algo.test( testset )\n",
    "\n",
    "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "\n",
    "predictions[:5]\n",
    "# test()의 경우 사용자-아이템 평점 데이터 셋 전체에 대해서 추천을 예측한다.\n",
    "# 반환된 리스트 객체는 25,000개의 prediction 객체를 내부에 가지고 있다.\n",
    "# test()는 모든 사용자와 아이템 아이디에 대해서 predict()를 반복적으로 수행한 결과이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.6189169617429, {'was_impossible': False}),\n",
       " ('882', '291', 3.6235797360547557, {'was_impossible': False}),\n",
       " ('535', '507', 4.177448313971358, {'was_impossible': False})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 속성 확인\n",
    "[ (pred.uid, pred.iid, pred.est, pred.details) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9480667439638305"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "\n",
    "# 성능 평가\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprise는 사용자 아이디, 아이템 아이디, 평점 데이터가 로우 레벨로 된 데이터 셋만 적용 가능하다.\n",
    "# 만약 user_id, item_id, rating, time_stamp로 구성된 데이터가 있다면 앞 3개 컬럼만 로딩한다.\n",
    "# 일반 데이터 파일이나 판다스 데이터 프레임도 로딩 가능하나 컬럼 순서가 반드시 사용자 아이디, 아이템 아이디, 평점 순이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_builtin()으로 무비렌즈 데이터를 불러올 수 있다.\n",
    "# 디폴트로 ml-100k(10만 개 평점 데이터)를 불러오며 ml-1M(100만 개 평점 데이터)를 불러 올 수 있다.\n",
    "# load_from_file()은 OS 파일을 로딩할 때 사용한다.\n",
    "# 주의할 점은 원본 파일에 컬럼명이 없어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index와 header를 제거한 ratings_noh.csv 파일 생성\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "ratings.to_csv('./data/ratings_noh.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 user_id, item_id, rating, time_stamp로 구성된 데이터가 있다면 앞 3개 컬럼만 로딩한다.\n",
    "# 일반 데이터 파일이나 판다스 데이터 프레임도 로딩 가능하나 컬럼 순서가 반드시 사용자 아이디, 아이템 아이디, 평점 순이어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_builtin()으로 무비렌즈 데이터를 불러올 수 있다.\n",
    "# 디폴트로 ml-100k(10만 개 평점 데이터)를 불러오며 ml-1M(100만 개 평점 데이터)를 불러 올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_from_file()은 OS 파일을 로딩할 때 사용한다.\n",
    "# 주의할 점은 원본 파일에 컬럼명이 없어야 한다.\n",
    "# index와 header를 제거한 ratings_noh.csv 파일 생성\n",
    "ratings = pd.read_csv('./data/ratings.csv')\n",
    "ratings.to_csv('./data/ratings_noh.csv', index=False, header=False)\n",
    "# ratings.csv에서 index와 header를 제거한 원본 파일을 생성하였다.\n",
    "# 이 데이터는 userid, movieid, rating, timestamp로 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x124277ec508>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "# Reader 객체 생성\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "# surprise 데이터 셋은 기본적으로 무비렌즈 데이터 형식을 따른다.\n",
    "# 무비렌즈 데이터 형식이 아닌 다른 OS 파일은 Reader() 클래스를 먼저 설정하여야 한다.\n",
    "# line_format: 컬럼을 순서대로 나열한다(컬럼명은 공백으로 분리).\n",
    "# sep: 구분자로 디폴트는 \\t이다.\n",
    "# rating_scale: 평점 값의 최소, 최대를 설정한다(디폴트는 1,5).\n",
    "# Reader() 객체를 입력해 데이터를 불러온다.\n",
    "data = Dataset.load_from_file('./data/ratings_noh.csv', reader=reader)\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# surprise의 train_test_split() 사용\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=0)\n",
    "\n",
    "# SVD를 이용한 잠재 요인 협업 필터링 (잠재 요인 크기 = 50)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 추천 예측 평점 (.test)\n",
    "predictions = algo.test( testset )\n",
    "\n",
    "# 성능 평가\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load_from_df()을 이용하여 데이터 프레임을 surprise 데이터 셋으로 로딩 가능하다.\n",
    "# 주의할 점은 컬럼 순서가 반드시 사용자 아이디, 아이템 아이디, 평점 순이어야 한다.\n",
    "# 데이터 불러오기 (데이터 프레임)\n",
    "ratings = pd.read_csv('./data/ratings.csv') \n",
    "\n",
    "# Reader 객체 생성\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# 사용자 아이디, 아이템 아이디, 평점 순서 (원래는 timestamp도 있으나 제외)\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# surprise의 train_test_split() 사용\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# SVD를 이용한 잠재 요인 협업 필터링 (잠재 요인 크기 = 50)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 추천 예측 평점 (.test)\n",
    "predictions = algo.test( testset )\n",
    "\n",
    "# 성능 평가\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8694  0.8768  0.8809  0.8651  0.8736  0.8732  0.0055  \n",
      "MAE (testset)     0.6669  0.6736  0.6774  0.6655  0.6719  0.6710  0.0044  \n",
      "Fit time          8.83    7.24    7.95    7.30    7.30    7.72    0.61    \n",
      "Test time         0.28    0.21    0.36    0.18    0.20    0.25    0.07    \n",
      "Runtime: 40.90 초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from surprise.model_selection import cross_validate \n",
    "\n",
    "\n",
    "# 데이터 불러오기 (데이터 프레임)\n",
    "ratings = pd.read_csv('./data/ratings.csv') \n",
    "\n",
    "# Reader 객체 생성\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# 사용자 아이디, 아이템 아이디, 평점 순서 (원래는 timestamp도 있으나 제외)\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# SVD를 이용한 잠재 요인 협업 필터링\n",
    "algo = SVD(random_state=0)\n",
    "\n",
    "start = time.time()\n",
    "# 교차 검증 수행\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "# surprise.model_selection의 cross_validate()으로 교차 검증이 가능하다.\n",
    "end = time.time()\n",
    "print('Runtime: {0:.2f} 초'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터\n",
    "- GridSearchCV()로 하이퍼 파라미터 튜닝이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 379.16 초\n",
      "{'n_epochs': 20, 'n_factors': 50}\n",
      "0.8770074214446367\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# n_epochs: SGD 수행 시 반복 횟수, n_factors: 잠재 요인 크기\n",
    "param_grid = {\n",
    "    'n_epochs': [20, 40, 60], \n",
    "    'n_factors': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3) # algo가 아닌 SVD 입력하였다.\n",
    "\n",
    "start = time.time()\n",
    "gs.fit(data)\n",
    "end = time.time()\n",
    "print('Runtime: {0:.2f} 초'.format(end-start))\n",
    "\n",
    "# 최적 하이퍼 파라미터 및 그 때의 최고 성능\n",
    "print(gs.best_params['rmse'])\n",
    "print(gs.best_score['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오류 코드\n",
    "# 실습 데이터는 ratings.csv를 train, test 분리 없이 전체로 사용한다.\n",
    "# 다만 surprise는 TrainSet 객체로 변환하지 않으면 fit()으로 학습시 오류가 발생한다.\n",
    "# data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "# algo = SVD(n_factors=50, random_state=0)\n",
    "# algo.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x12424886448>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DatasetAutoFolds() 객체를 생성 후 build_full_trainset() 메서드를 호출하면 전체 데이터를 학습 데이터로 만들 수 있음\n",
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "# Reader 객체 생성\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "\n",
    "# DatasetAutoFolds 객체 생성\n",
    "data_folds = DatasetAutoFolds(ratings_file='./data/ratings_noh.csv', reader=reader)\n",
    "\n",
    "# 전체 데이터를 train으로 지정\n",
    "trainset = data_folds.build_full_trainset()\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# SVD를 이용한 잠재 요인 협업 필터링 (잠재 요인 크기 = 50)\n",
    "model = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "model.fit(trainset)  # 훈련\n",
    "\n",
    "# 사용자 아이디, 아이템 아이디 문자열로 입력\n",
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "# 추천 예측 평점 (.predict)\n",
    "pred = model.predict(uid, iid, verbose=True) # 9번 회원은 42번 영화를 추천한 적이 없으며 예측 점수는 3.13점이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영화에 대한 상세 속성 정보 DataFrame로딩\n",
    "movies = pd.read_csv('./data/movies.csv')\n",
    "\n",
    "# 아직 보지 않은 영화 리스트 함수\n",
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "     # 특정 userId가 평점을 매긴 모든 영화 리스트\n",
    "    seen_movies = ratings[ratings['userId']== userId]['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화명을 list 객체로 만듬. \n",
    "    total_movies = movies['movieId'].tolist()\n",
    "      \n",
    "    # 한줄 for + if문으로 안 본 영화 리스트 생성\n",
    "    unseen_movies = [ movie for movie in total_movies if movie not in seen_movies]\n",
    "    \n",
    "    # 일부 정보 출력\n",
    "    total_movie_cnt = len(total_movies)\n",
    "    seen_cnt = len(seen_movies)\n",
    "    unseen_cnt = len(unseen_movies)\n",
    "    \n",
    "    print(f\"전체 영화 수: {total_movie_cnt}, 평점 매긴 영화 수: {seen_cnt}, 추천 대상 영화 수: {unseen_cnt}\")\n",
    "    \n",
    "    return unseen_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 영화 수: 9742, 평점 매긴 영화 수: 46, 추천 대상 영화 수: 9696\n"
     ]
    }
   ],
   "source": [
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    \n",
    "    # 아직 보지 않은 영화의 예측 평점: prediction 객체 생성\n",
    "    predictions = []    \n",
    "    for movieId in unseen_movies:\n",
    "        predictions.append(algo.predict(str(userId), str(movieId)))\n",
    "    \n",
    "    # 리스트 내의 prediction 객체의 est를 기준으로 내림차순 정렬\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est #est: 예측평점\n",
    "\n",
    "    predictions.sort(key=sortkey_est, reverse=True) # key에 리스트 내 객체의 정렬 기준을 입력\n",
    "    \n",
    "    # 상위 top_n개의 prediction 객체\n",
    "    top_predictions = predictions[:top_n]\n",
    "    \n",
    "    # 영화 아이디, 제목, 예측 평점 출력\n",
    "    print(f\"Top-{top_n} 추천 영화 리스트\")\n",
    "    \n",
    "    for pred in top_predictions:\n",
    "        \n",
    "        movie_id = int(pred.iid) #영화 id\n",
    "        movie_title = movies[movies[\"movieId\"] == movie_id][\"title\"].tolist()\n",
    "        movie_rating = pred.est #평점 예측\n",
    "        \n",
    "        print(f\"{movie_title}: {movie_rating:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 추천 영화 리스트\n",
      "['Godfather, The (1972)']: 4.31\n",
      "['Star Wars: Episode IV - A New Hope (1977)']: 4.28\n",
      "['Pulp Fiction (1994)']: 4.28\n",
      "['Star Wars: Episode V - The Empire Strikes Back (1980)']: 4.23\n",
      "['Usual Suspects, The (1995)']: 4.19\n",
      "['Streetcar Named Desire, A (1951)']: 4.15\n",
      "['Star Wars: Episode VI - Return of the Jedi (1983)']: 4.12\n",
      "['Goodfellas (1990)']: 4.11\n",
      "['Glory (1989)']: 4.08\n",
      "['Silence of the Lambs, The (1991)']: 4.08\n"
     ]
    }
   ],
   "source": [
    "recomm_movie_by_surprise(model, 9, unseen_movies, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장및 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./ml-latest-small.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle # 파이썬 자료형 저장 지원\n",
    "import joblib # 병렬 프로그래밍, 모델 저장, 로딩\n",
    "\n",
    "joblib.dump(model, './ml-latest-small.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
